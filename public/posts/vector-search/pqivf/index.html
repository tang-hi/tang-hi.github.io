<!DOCTYPE html>
<html lang="en">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
<meta charset="UTF-8">

<script async src="https://www.googletagmanager.com/gtag/js?id=G-D5M6G40M25"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-D5M6G40M25');
</script>
<meta name="baidu-site-verification" content="codeva-vs6hGikUak" />
<title>PQIVF(Prodcut Quantization) | Don&#39;t Panic</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.123.7">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="Product Quantization是一种用于向量量化的方法，由Hervé Jégou和Olivier Chum于2011年在论文&lt;&lt;Product quantization for nearest neighbor search&gt;&gt;中首次提出。">
<link rel="stylesheet" type="text/css" media="screen" href="/css/normalize.css" />
<link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
<link rel="stylesheet" type="text/css" media="screen" href="/css/all.css" /><link rel="stylesheet" href="/css/katex.css" crossorigin="anonymous">
<script defer src="/js/katex.js"  integrity="sha384-PFWG8XW41D5NzhNv5FegM1CUkw9nNLdWug8DuwnUoNEVop9n5frjcnbtsZtxTNjw" crossorigin="anonymous"></script>
<script defer src="/js/auto-render.js" integrity="sha384-EN2q+JG5/3Z8gD7hT5WZqq+W+9wQR4P3IezfuZmGG5RkNXaaaks85seDJO7WkZlY" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script>
document.addEventListener("DOMContentLoaded", function() { renderMathInElement(document.body, { delimiters: [ {left: "$$", right: "$$", display: true}, {left: "$", right: "$", display: false} ] }); });
</script>




<meta property="og:title" content="PQIVF(Prodcut Quantization)" />
<meta property="og:description" content="Product Quantization是一种用于向量量化的方法，由Hervé Jégou和Olivier Chum于2011年在论文&lt;&lt;Product quantization for nearest neighbor search&gt;&gt;中首次提出。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/vector-search/pqivf/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-04-05T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="PQIVF(Prodcut Quantization)"/>
<meta name="twitter:description" content="Product Quantization是一种用于向量量化的方法，由Hervé Jégou和Olivier Chum于2011年在论文&lt;&lt;Product quantization for nearest neighbor search&gt;&gt;中首次提出。"/>

<meta itemprop="name" content="PQIVF(Prodcut Quantization)">
<meta itemprop="description" content="Product Quantization是一种用于向量量化的方法，由Hervé Jégou和Olivier Chum于2011年在论文&lt;&lt;Product quantization for nearest neighbor search&gt;&gt;中首次提出。"><meta itemprop="datePublished" content="2023-04-05T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-04-05T00:00:00+00:00" />
<meta itemprop="wordCount" content="141">
<meta itemprop="keywords" content="" />
</head>
<body>
<header>
<div id="avatar">
<a href="http://localhost:1313/"><img src="/avatar.jpeg" alt="Don&#39;t Panic"></a>
</div>
<div id="titletext">
<h2 id="titleonly"><a href="http://localhost:1313/">Don&#39;t Panic</a></h2>
</div>
<div id="title-social">
<div id="social">
<nav><ul>
<li><a href="https://github.com/tang-hi"><i title="Github" class="icons fab fa-github"></i></a></li>
<li><a href="mailto:tangdhcs@gmail.com"><i title="Email" class="icons fas fa-envelope"></i></a></li>
<li><a href="https://twitter.com/TangDh"><i title="Twitter" class="icons fab fa-twitter"></i></a></li>
<li><a href="/index.xml"><i title="RSS" class="icons fas fa-rss"></i></a></li>
<li><a><i title="Switch Dark Mode" class="dark-mode icons fas fa-moon"></i></a></li>
</ul></nav>
</div>
</div>
<div id="mainmenu">
<nav>
<ul>
<li><a href="/">Home</a></li>
<li><a href="/posts">All Posts</a></li>
<li><a href="/about">About</a></li>
<li><a href="/categories">Categories</a></li>
</ul>
</nav>
</div>
</header>
<main>
<div class="post">
<article>
<div class="post-header">
<div class="meta">
<div class="date">
<span class="day">05</span>
<span class="rest">Apr 2023</span>
</div>
</div>
<div class="matter">
<h1 class="title">PQIVF(Prodcut Quantization)</h1>
<p class="post-meta">
<span class="post-meta">

&nbsp;<i class="fas fa-clock"></i>&nbsp;1&nbsp;minutes


 
&nbsp;| &nbsp;

<i class="fas fa-book"></i>&nbsp;141&nbsp;words




</span>

</p>
</div>
</div>
<div class="markdown">
<p>Product Quantization是一种用于向量量化的方法，由Hervé Jégou和Olivier Chum于2011年在论文<a href="https://lear.inrialpes.fr/pubs/2011/JDS11/jegou_searching_with_quantization.pdf" target="_blank">《Product quantization for nearest neighbor search》</a>中首次提出。这篇论文解决了在大规模数据集上进行最近邻搜索的问题。相较于其他的ANN搜索算法通过牺牲一定的内存空间来减少搜索空间，PQ通过对向量进行量化压缩，使得所需要的内存空间大幅减小。</p>
<h3 id="what-is-product-quantization">What is Product Quantization?</h3>
<p>如果想要搞清楚PQ，那么首先得明白 <strong>Quantization</strong> 的含义，Quantization即量化，这是一个从信号处理领域来的名词，按照Wikipedia的定义</p>
<blockquote>
<p>Quantization is the process of constraining an input from a continuous or otherwise large set of values to a discrete set (such as the integers).</p>
</blockquote>
<p>量化就是将一个集合映射到另一个离散的集合之中，那么PQ实际上就是将数据集中的每一个向量映射到另一个集合中，比如说整数集合。即</p>
<div style="text-align: center">
<img src="/pic/PQ1.png"/>
</div>
<p>通过这种方式我们可以用一个INT来表示整个向量，也就是说如果向量原来的维数为128.那么单个向量的内存占用就会从128 * 4 byte (float) 降低为 4 byte(int), 内存可以减少<strong>128</strong>倍。<strong>但是量化要求我们的映射为满射，即被映射的集合中任一元素，原始集合中至少存在一个元素与之对应</strong>。也就是说如果我们将向量映射到整个<code>LONG</code>空间，我们会有<code>LONG_MAX * 8 byte</code> 即<strong>18,446GB</strong>的内存占用，这显然是不可接受的。那如果我们仅将向量映射到<code>UINT8</code>,我们会有 <code>256 * 2 byte</code> 即<strong>512B</strong>的内存占用，内存问题看似解决了。但是如果我们数据集中有100万个向量，我们将其映射到0-255，平均一个整数有3906个向量与其对应，我们在搜索时无法区分这3906个向量与待查询向量之间的距离差别，这就会导致糟糕的召回率。因此选择一个合适的映射空间大小，使得内存占用以及召回率达到一个sweet point，这就是PQ所要达成的效果。</p>
<blockquote>
<p>请注意，Product Quantization并不是通过降维来减少空间大小。</p>
<p>在Product Quantization中量化后向量的数量仍然保持不变。但是，压缩后的向量值现在被转换为一个小整数，你可以认为这个整数仅仅只是一个符号。通过将高维向量转化为一个符号，从而减少了向量的内存空间占用。</p>
</blockquote>
<h3 id="how-product-quantization-work">How Product Quantization Work?</h3>
<h3 id="1-split-and-train">1. Split And Train</h3>
<p>假设向量的维数为128,我们首先将该向量平均分为8份，每一个的维数为16。</p>
<div style="text-align: center">
<img src="/pic/PQ2.png"/>
</div>
<p>如果我们有1000个向量，我们将每一份向量平均分为8份，V0, V1&hellip;. V7。那么我们会有1000个V0, 1000个V1,&hellip;1000个V7。我们分别对他们进行<strong>K-means</strong>聚类，同时假定我们选定K-means的<strong>K</strong>为256。那么我们在每一个Vi中会得到256个centroids。</p>
<div style="text-align: center">
<img src="/pic/PQ3.png"/>
</div>
<h3 id="2-encode">2. Encode</h3>
<p>在得到centroids后，我们为每一个向量进行编码，我们首先分别对V0,V1,&hellip;.V7进行编码，编码的规则相当简单。我们拿V0进行举例，首先我们遍历V0中每一个向量，并且选择距离当前向量最近的一个centroids作为其对应的编码值，如果向量A距离centroids42最近，那么A的编码值即为42。在完成V0,V1&hellip;.V7的编码值后，我们将其拼接起来就会得到所有向量的编码值。</p>
<div style="text-align: center">
<img src="/pic/PQ4.png"/>
</div>
<h4 id="summary">Summary</h4>
<p>目前PQ的构建部分已经讲完了，我们现在重新审视一下PQ这个算法，首先考虑PQ的映射空间大小，尽管我们单个Vi只有256个质心，也就是说无论向量有多少，它们只会映射到0-255,但是我们通过对向量进行split，使得整体的映射空间大小为 $256^M$ (M为向量被split的份数), 从而极大的扩充了映射空间的大小，那我们再考虑内存占用的大小，V0占用的空间大小为$N * 2 byte$ 整体的空间大小为$M * N * 2 byte$, 相比于原始的大小$ N * D * 4bytes$极大的减小了内存占用(D 为向量的维数)。因此PQ在保证了内存占用低的同时提供了一个较大的映射空间，从而保证了召回率。</p>
<h3 id="3-search">3. Search</h3>
<p>当我们已经对数据库中的所有向量都已经进行了量化，我们需要在用户给定任意向量后，从数据库中寻找与该向量最相似的N个向量，首先我们仍旧对query进行split。</p>
<div style="text-align: center">
<img src="/pic/PQ5.png"/>
</div>
<blockquote>
<p>注意我们不会对Query进行量化，仅仅只做Split，原因是这样子可以在距离计算时保证更高的精度，详情可以参考论文原文</p>
</blockquote>
<p>在Split后，我们会计算对应的Split部分与每一个centroids的距离，并将该距离进行保存。</p>
<div style="text-align: center">
<img src="/pic/PQ6.png"/>
</div>
<p>随后我们遍历数据库中所有的向量，通过查表分别计算出Query中每一段与他们之间的距离，随后相加得到最终的距离，并最终选择距离最近的K个向量。</p>
<div style="text-align: center">
<img src="/pic/PQ7.png"/>
</div>
<h3 id="4-ivf">4. IVF</h3>
<p>尽管PQ大幅减少了我们所需要的内存，但是在搜索时，我们仍然需要与数据集中的每一个向量计算他们之间的距离，因此我们希望可以在保证召回率的同时，减少计算量。为此我们引入了IVF(Inverted File Index), 首先我们先对数据集中的向量进行k-means聚类，从而将数据集划分为k个小数据集，同时计算数据集中的向量与其对应的质心之间的残差，并对残差进行PQ压缩。</p>
<div style="text-align: center">
<img src="/pic/PQ8.png"/>
</div>
需要注意的是每一个centroid后面都会挂载属于这个分区的向量，但这向量不是数据集中的原始向量，而是原始向量与centroid的残差。之所以选择残差是因为这样可以降低数据集中的方差，从而在进行ANN搜索时，距离计算的误差也会更小，从而产生更好的搜索质量。
<div style="text-align: center">
<img src="/pic/PQ9.png"/>
</div>
<p>可以认为我们实际上是将整个数据集划分为几个更小的数据集后，再对每一个分区进行PQ压缩。当我们搜索时，我们会选择<code>probe</code>个距离最近的分区(通过计算与centroid之间的距离决定),同样的计算Query与对应centroid的残差，并使用这个残差在该分区进行PQ搜索，在完成所有分区的搜索后，返回距离最近的K个向量。</p>
<div style="text-align: center">
<img src="/pic/PQ10.png"/>
</div>
<p>这里之所以选择<code>probe</code>个距离最近的分区而不是选择最近的那一个分区，是因为作者在论文中提到</p>
<blockquote>
<p>The query vector and its nearest neighbors are often not quantized to the same partition centroid, but to nearby ones</p>
</blockquote>
<p>因此为了召回率我们会扩大一部分的搜索范围，因此probe的数量也体现了召回率与搜索速度之间的tradeoff。</p>
<h3 id="5-summary">5. Summary</h3>
<p>PQ通过对向量进行量化，降低向量搜索时所使用的内存，同时通过对向量分段量化，扩展映射空间。而IVF在PQ的基础上进一步减少搜索空间，从而降低了搜索时间。</p>

</div>
<div class="tags">
<div class="taxosfloating_left">
<p>Categories</p>
</div>
<div class="termsfloating_right">
<p>
<a href="/categories/vector%20search/">vector search</a>
</p>
</div>
<div class="clearit"></div>
</div>
<div id="disqus_thread"></div>
<script type="text/javascript">
(function() {


if (window.location.hostname == "localhost")
  return;
var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
var disqus_shortname = 'tangdh-life';
dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to load the comments.</noscript>


</article>
</div>
</main><script src="/js/dark-mode.js"></script>

</body>
</html>
